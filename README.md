# ðŸ§  DeepSeek Fine-Tuning Framework

This repository provides a lightweight pipeline for fine-tuning [DeepSeek](https://huggingface.co/deepseek-ai) and other instruction-tuned LLMs using curated, token-efficient datasets. An example model training plot can be seen [here](https://wandb.ai/asantucci-stanford-university/deepseek%20training/reports/Example-loss-curve--VmlldzoxMjI2OTk0OQ).

## ðŸš€ Features

- âœ… Shard-based streaming dataloaders (10B Token Sample of `FineWeb-EDU`)
- âœ… LoRa, KV-caching, RoPE, MoE...
- âœ… Interactive chat UI available for fine-tuned model.

## Limitations
- ðŸš« Currently does not start with a pre-trained model.
- ðŸš« ...